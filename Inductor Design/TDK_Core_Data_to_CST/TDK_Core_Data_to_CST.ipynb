{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cd166b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aef5abe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: N87_Permeability_interp_FIX2.txt (frequency in Hz)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Inputs ---\n",
    "excel_path = \"N87_Permeability.xlsx\"      # change if needed\n",
    "output_path = \"N87_Permeability_interp_FIX2.txt\"\n",
    "\n",
    "# --- Load ---\n",
    "df = pd.read_excel(excel_path)\n",
    "\n",
    "# --- Clean Series1 (Mu') source: remove nonpositive freq / NaNs, sort, dedupe ---\n",
    "s1 = df[[\"Series1.X\", \"Series1.Y\"]].copy()\n",
    "s1 = s1[(s1[\"Series1.X\"] > 0) & (s1[\"Series1.Y\"].notna())]\n",
    "s1 = s1.sort_values(\"Series1.X\").drop_duplicates(subset=\"Series1.X\", keep=\"last\")\n",
    "\n",
    "# Convert frequency from kHz -> Hz\n",
    "x1_hz = s1[\"Series1.X\"].astype(float).to_numpy() * 1e3  # original μ′ freqs (Hz)\n",
    "y1    = s1[\"Series1.Y\"].astype(float).to_numpy()        # original μ′\n",
    "\n",
    "# Reference frequency axis & μ″ from Series2, convert kHz -> Hz\n",
    "f_hz = pd.to_numeric(df[\"Series2.X\"], errors=\"coerce\").to_numpy() * 1e3  # Hz\n",
    "mu2  = pd.to_numeric(df[\"Series2.Y\"], errors=\"coerce\").to_numpy()        # μ″\n",
    "\n",
    "# Keep only finite, positive frequencies on the reference axis\n",
    "m_ref = np.isfinite(f_hz) & (f_hz > 0) & np.isfinite(mu2)\n",
    "f_hz = f_hz[m_ref]\n",
    "mu2  = mu2[m_ref]\n",
    "\n",
    "# --- Interpolate μ′ onto the reference freq axis (Hz) ---\n",
    "# Inside range: interpolate; below min: hold first value; above max: set to 0\n",
    "mu1 = np.interp(f_hz, x1_hz, y1, left=y1[0], right=y1[-1])\n",
    "mu1[f_hz > x1_hz.max()] = 0.0\n",
    "\n",
    "# --- Save (no headers, tab-separated). 'f' is in SI units (Hz) ---\n",
    "out = pd.DataFrame({\"f\": f_hz, \"Mu'\": mu1, \"Mu''\": mu2})\n",
    "out.to_csv(output_path, sep=\"\\t\", index=False, header=False, float_format=\"%.9f\")\n",
    "print(f\"Saved: {output_path} (frequency in Hz)\")\n",
    "\n",
    "# --- Plot complex permeability ---\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# μ′: original dots (Series1) and interpolated line (on Series2 grid)\n",
    "plt.semilogx(x1_hz, y1, 'o', label=\"μ′ original (Series1)\", markersize=4, alpha=0.7)\n",
    "plt.semilogx(f_hz,  mu1, '-', label=\"μ′ interpolated → Series2 grid\", linewidth=2)\n",
    "\n",
    "# μ″: original dots (Series2) and connected line\n",
    "plt.semilogx(f_hz, mu2, 'o', label=\"μ″ original (Series2)\", markersize=4, alpha=0.7)\n",
    "plt.semilogx(f_hz, mu2, '-', label=\"μ″ line\", linewidth=1)\n",
    "\n",
    "plt.xlabel(\"Frequency [Hz]\")\n",
    "plt.ylabel(\"Permeability\")\n",
    "plt.title(\"Complex Permeability vs Frequency (original dots & interpolated lines)\")\n",
    "plt.grid(True, which=\"both\", ls=\"-\", alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "594d05c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated μ_i (from initial curve) = 4505.0\n",
      "Estimated J_s (from initial curve) = 0.388054 T\n",
      "c sweep: 2 → 3 with 5 values\n",
      "Exported 5 CST tables to: C:\\Python_Sripts\\Core_Calculations\\out\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Initial B(H) analytical curves from hysteresis — sweep 'c' values (CST-like)\n",
    "\n",
    "Input (Excel with X=H [A/m], Y=B [mT]):  BH_FILE = \"N87_BH.xlsx\"\n",
    "Model: B(H) = μ0 H + J(H),  J(H) = Js * x / (1 + x^c)^(1/c),  x = H / H0,  H0 = Js/(μ0(μi-1))\n",
    "\n",
    "What it does:\n",
    "  • Extracts a clean first-quadrant, monotone initial curve (used only for parameter estimation)\n",
    "  • Estimates μᵢ (low-field slope) and Jₛ (high-field asymptote) from that initial curve\n",
    "  • Sweeps c ∈ [C_MIN, C_MAX] with N_C values, plots curves, exports one CST file per c\n",
    "  • Raw B–H scatter is large and drawn last (on top). The extracted curve is NOT plotted.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------------- User controls ----------------\n",
    "BH_FILE    = \"N87_BH.xlsx\"\n",
    "\n",
    "# c sweep\n",
    "C_MIN      = 2\n",
    "C_MAX      = 3\n",
    "N_C        = 5\n",
    "\n",
    "# Estimation knobs (on extracted initial curve)\n",
    "LOW_FIELD_FRAC  = 0.02   # fraction of max(H_init) for μi slope fit\n",
    "HIGH_FIELD_FRAC = 0.90   # lower bound fraction of H_init range for Js estimate\n",
    "\n",
    "# Export\n",
    "EXPORT_ALL = True\n",
    "OUT_DIR    = Path(\"out\")\n",
    "N_EXPORT   = 500\n",
    "H_MAX_FACTOR = 1.05\n",
    "\n",
    "# Plot style\n",
    "FIG_SIZE    = (10, 7)\n",
    "FONT_SIZE   = 18\n",
    "LEGEND_SIZE = 14\n",
    "LINE_WIDTH  = 2.4\n",
    "MARKER_SIZE = 10  # bigger scatter\n",
    "\n",
    "# ------------------------------------------------\n",
    "mu0 = 4e-7 * math.pi\n",
    "\n",
    "def load_bh_excel(path: str | Path):\n",
    "    df = pd.read_excel(path)\n",
    "    H = pd.to_numeric(df[\"X\"], errors=\"coerce\").to_numpy()\n",
    "    BmT = pd.to_numeric(df[\"Y\"], errors=\"coerce\").to_numpy()\n",
    "    m = np.isfinite(H) & np.isfinite(BmT)\n",
    "    H = H[m]; B = (BmT[m] * 1e-3)\n",
    "    idx = np.argsort(H)\n",
    "    return H[idx], B[idx]\n",
    "\n",
    "def extract_initial_from_bh(H: np.ndarray, B: np.ndarray):\n",
    "    \"\"\"First quadrant ascending branch; enforce monotone B(H).\"\"\"\n",
    "    m = H >= 0\n",
    "    Hq = H[m]; Bq = B[m]\n",
    "    keepH, keepB = [], []\n",
    "    lastH, lastB = -1e99, -1e99\n",
    "    for h, b in zip(Hq, Bq):\n",
    "        if h > lastH:\n",
    "            if b < lastB:\n",
    "                b = lastB\n",
    "            keepH.append(float(h)); keepB.append(float(b))\n",
    "            lastH, lastB = h, b\n",
    "    Hs = np.array(keepH, float)\n",
    "    Bs = np.array(keepB, float)\n",
    "    return Hs, Bs\n",
    "\n",
    "def linear_fit(x, y):\n",
    "    A = np.vstack([x, np.ones_like(x)]).T\n",
    "    m, b = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "    return float(m), float(b)\n",
    "\n",
    "def estimate_mu_i(Hs: np.ndarray, Bs: np.ndarray):\n",
    "    if Hs.size < 4:\n",
    "        return 1000.0\n",
    "    Hcut = max(1e-9, LOW_FIELD_FRAC * Hs.max())\n",
    "    sel = Hs <= Hcut\n",
    "    if sel.sum() < 6:\n",
    "        k = min(max(6, int(0.1*Hs.size)), Hs.size)\n",
    "        x, y = Hs[:k], Bs[:k]\n",
    "    else:\n",
    "        x, y = Hs[sel], Bs[sel]\n",
    "    s0, _ = linear_fit(x, y)\n",
    "    return max(1.0, s0 / mu0)\n",
    "\n",
    "def estimate_Js(Hs: np.ndarray, Bs: np.ndarray):\n",
    "    if Hs.size < 5:\n",
    "        return float(np.max(Bs) - mu0*np.max(Hs))\n",
    "    Hthr = Hs.min() + HIGH_FIELD_FRAC * (Hs.max() - Hs.min())\n",
    "    sel = Hs >= Hthr\n",
    "    if sel.sum() < 5:\n",
    "        sel = np.zeros_like(Hs, dtype=bool)\n",
    "        sel[-max(5, Hs.size//10):] = True\n",
    "    J = Bs[sel] - mu0*Hs[sel]\n",
    "    return float(np.mean(np.clip(J, 0.0, None)))\n",
    "\n",
    "def analytical_J(H: np.ndarray, mu_i: float, Js: float, c: float):\n",
    "    H0 = Js / (mu0 * max(mu_i - 1.0, 1e-9))\n",
    "    x = np.maximum(H, 0.0) / max(H0, 1e-30)\n",
    "    return Js * (x / np.power(1.0 + np.power(x, c), 1.0/c))\n",
    "\n",
    "# ---------------- Pipeline ----------------\n",
    "# Load raw BH and build initial curve (used for parameter estimation only)\n",
    "H_raw, B_raw = load_bh_excel(BH_FILE)\n",
    "H_init, B_init = extract_initial_from_bh(H_raw, B_raw)\n",
    "\n",
    "# Estimate μi and Js from the extracted initial curve\n",
    "mu_i = estimate_mu_i(H_init, B_init)\n",
    "Js   = estimate_Js(H_init, B_init)\n",
    "\n",
    "# Prepare H grid for model curves and (optional) exports\n",
    "Hmax = H_init.max() * H_MAX_FACTOR if H_init.size else H_raw.max() * H_MAX_FACTOR\n",
    "H_grid = np.linspace(0.0, max(Hmax, 1.0), N_EXPORT)\n",
    "\n",
    "# c values\n",
    "cs = np.linspace(C_MIN, C_MAX, N_C)\n",
    "\n",
    "# Export directory\n",
    "if EXPORT_ALL:\n",
    "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=FIG_SIZE)\n",
    "\n",
    "for c in cs:\n",
    "    B_model = mu0*H_grid + analytical_J(H_grid, mu_i, Js, float(c))\n",
    "    # export per c\n",
    "    if EXPORT_ALL:\n",
    "        fname = OUT_DIR / f\"initial_BH_c_{c:.3f}.txt\"\n",
    "        pd.DataFrame({\"H\": H_grid, \"B\": B_model}).to_csv(\n",
    "            fname, sep=\"\\t\", index=False, header=False, float_format=\"%.9f\"\n",
    "        )\n",
    "    # plot curves\n",
    "    plt.plot(H_grid, B_model, lw=LINE_WIDTH, label=f\"Analytical (c={c:.2f})\")\n",
    "\n",
    "# draw scatter LAST so it's on top\n",
    "plt.scatter(H_raw, B_raw, s=MARKER_SIZE**2, alpha=0.65, label=\"Raw B–H (scatter)\", zorder=5)\n",
    "\n",
    "print(f\"Estimated μ_i (from initial curve) = {mu_i:.1f}\")\n",
    "print(f\"Estimated J_s (from initial curve) = {Js:.6f} T\")\n",
    "print(f\"c sweep: {C_MIN} → {C_MAX} with {N_C} values\")\n",
    "if EXPORT_ALL:\n",
    "    print(f\"Exported {N_C} CST tables to: {OUT_DIR.resolve()}\")\n",
    "\n",
    "plt.xlabel(\"H [A/m]\", fontsize=FONT_SIZE)\n",
    "plt.ylabel(\"B [T]\", fontsize=FONT_SIZE)\n",
    "plt.title(\"Initial Magnetization Curve — c sweep\", fontsize=FONT_SIZE+2)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(fontsize=LEGEND_SIZE)\n",
    "plt.xticks(fontsize=FONT_SIZE-2); plt.yticks(fontsize=FONT_SIZE-2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddc6e6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CST curve for c=2.500 → C:\\Python_Sripts\\Core_Calculations\\out\\initial_BH_c_2.500.txt\n"
     ]
    }
   ],
   "source": [
    "# === Cell 2: Export CST table for a manually chosen c ===\n",
    "# Assumes Cell 1 already defined: mu0, analytical_J(), mu_i, Js, H_grid (or H_raw/H_init + H_MAX_FACTOR), pd, np, Path\n",
    "\n",
    "# ---- User input ----\n",
    "C_SELECTED = 2.5                        # <--- try your chosen c here\n",
    "OUT_DIR = Path(\"out\")                     # same folder you used before (or change)\n",
    "OUT_FILE_SINGLE = OUT_DIR / f\"initial_BH_c_{C_SELECTED:.3f}.txt\"\n",
    "N_EXPORT = 500                            # points in exported curve (override if you like)\n",
    "\n",
    "# ---- Rebuild H_grid if it's not available (safe fallback) ----\n",
    "if 'H_grid' not in globals():\n",
    "    # If raw/init data exist, use their range; else fall back to a generic range\n",
    "    if 'H_raw' in globals() and 'H_init' in globals() and 'H_MAX_FACTOR' in globals():\n",
    "        Hmax = float(max(np.max(H_raw), np.max(H_init)) * H_MAX_FACTOR)\n",
    "        H_grid = np.linspace(0.0, max(Hmax, 1.0), N_EXPORT)\n",
    "    else:\n",
    "        H_grid = np.linspace(0.0, 1e4, N_EXPORT)  # generic fallback\n",
    "\n",
    "# ---- Compute model curve for the chosen c ----\n",
    "B_model = mu0 * H_grid + analytical_J(H_grid, mu_i, Js, float(C_SELECTED))\n",
    "\n",
    "# ---- Export (CST format: \"H [A/m] \\t B [T]\" with no header) ----\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "import pandas as pd\n",
    "pd.DataFrame({\"H\": H_grid, \"B\": B_model}).to_csv(\n",
    "    OUT_FILE_SINGLE, sep=\"\\t\", index=False, header=False, float_format=\"%.9f\"\n",
    ")\n",
    "\n",
    "print(f\"Saved CST curve for c={C_SELECTED:.3f} → {OUT_FILE_SINGLE.resolve()}\")\n",
    "\n",
    "# ---- Optional quick overlay plot (comment out if not needed) ----\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(9,6))\n",
    "if 'H_init' in globals() and 'B_init' in globals():\n",
    "    plt.plot(H_init, B_init, lw=2.2, label=\"Extracted initial (data)\")\n",
    "plt.plot(H_grid, B_model, lw=2.6, label=f\"Analytical (c={C_SELECTED:.2f})\")\n",
    "plt.xlabel(\"H [A/m]\"); plt.ylabel(\"B [T]\"); plt.title(\"Initial B(H) — selected c\")\n",
    "plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67cfa167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best HN parameters (single term, CST-safe):\n",
      "  mu_infinity      = 42.2\n",
      "  mu_static (def.) = 11371   (Δμ = 11328.8)\n",
      "  tau [s]          = 5.164670e-08\n",
      "  alpha            = 0.999  (< 1.0)\n",
      "  beta             = 1\n",
      "  Score            = 0.959507\n",
      "  Sanity: predicted f_peak ≈ 3.08e+06 Hz,  μ\"_max ≈ 5664.41\n",
      "\n",
      "Estimated tolerances in the fit band:\n",
      "  Reactance / inductance (≈ μ′): median ±22.9%, max ±773.2%\n",
      "  Core loss / ESR (≈ μ″):       median ±38.4%, max ±103.3%\n",
      "  Suggested loss scale (meas/model): median ×1.49, 90th pct ×1.80\n",
      "\n",
      "Files:\n",
      "  User export      : N87_Permeability_User_For_CST.txt\n",
      "  Best params CSV  : N87_HN_params_best.csv\n",
      "  Leaderboard CSV  : N87_HN_leaderboard.csv\n",
      "  Best-fit plot    : N87_HN_fit_best.png\n",
      "  Error plot       : N87_HN_fit_errors.png\n",
      "\n",
      "Paste μ∞, μs (default), τ, α, β into CST → Magnetic → Dispersion → Generalized Debye,\n",
      "then enable Field dependency → B–H curve to include saturation.\n",
      "Use the loss scale factor to bracket temperature rise/efficiency if needed.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "N87 → CST 'User' export + single-term Generalized Debye (Havriliak–Negami) auto-fit\n",
    "\n",
    "- Exports CST 'User' file: f[Hz], μ′, μ″\n",
    "- Auto-tunes a CST-safe single HN term (band/weights/α/β/restarts)\n",
    "- Saves best params + fit plot + leaderboard\n",
    "- Prints tolerance estimates for μ′ (→ X_L), μ″ (→ ESR_core), and loss scale factor\n",
    "- NEW: error-vs-frequency plot uses LOG y-axis of ABSOLUTE % error (semilogy)\n",
    "\n",
    "Kernel uses e^{-jωt}: μ* = μ′ − j μ″ (so μ″ ≥ 0 for passive media).\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "# ---------- Paths ----------\n",
    "EXCEL_PATH   = Path(\"N87_Permeability.xlsx\")\n",
    "USER_OUT     = Path(\"N87_Permeability_User_For_CST.txt\")\n",
    "BEST_PARAMS  = Path(\"N87_HN_params_best.csv\")\n",
    "BEST_PNG     = Path(\"N87_HN_fit_best.png\")\n",
    "ERROR_PNG    = Path(\"N87_HN_fit_errors.png\")\n",
    "LEADERBOARD  = Path(\"N87_HN_leaderboard.csv\")\n",
    "\n",
    "# ---------- Auto-tune grids ----------\n",
    "BAND_SPREADS = [(1/12, 8), (1/8, 8), (1/6, 6), (1/4, 4)]\n",
    "MU_PP_WEIGHTS = [2.0, 3.0, 4.0, 5.0]\n",
    "ALPHA_MODES   = [(\"frozen\", 0.999), (\"free\", None)]\n",
    "BETA_MODES    = [(\"frozen\", 1.0),   (\"free\",  None)]\n",
    "RESTARTS      = [(0.5, 0.7, 0.9), (1.0, 1.0, 1.0), (2.0, 1.5, 1.1)]\n",
    "\n",
    "# ---------- Plot look ----------\n",
    "X_SCALE = \"log\"\n",
    "Y_SCALE = \"linear\"\n",
    "\n",
    "# =====================================================================\n",
    "# Data I/O\n",
    "# =====================================================================\n",
    "def load_excel(path: Path):\n",
    "    df = pd.read_excel(path)\n",
    "    req = [\"Series1.X\", \"Series1.Y\", \"Series2.X\", \"Series2.Y\"]\n",
    "    miss = [c for c in req if c not in df.columns]\n",
    "    if miss:\n",
    "        raise ValueError(f\"Missing expected columns: {miss}\")\n",
    "    s1 = (df[[\"Series1.X\", \"Series1.Y\"]]\n",
    "          .replace([np.inf, -np.inf], np.nan).dropna())\n",
    "    s1 = s1[s1[\"Series1.X\"] > 0].sort_values(\"Series1.X\").drop_duplicates(\"Series1.X\", keep=\"last\")\n",
    "    f1_hz   = s1[\"Series1.X\"].to_numpy(float) * 1e3\n",
    "    mu1_src = s1[\"Series1.Y\"].to_numpy(float)\n",
    "\n",
    "    s2 = (df[[\"Series2.X\", \"Series2.Y\"]]\n",
    "          .replace([np.inf, -np.inf], np.nan).dropna())\n",
    "    s2 = s2[s2[\"Series2.X\"] > 0].sort_values(\"Series2.X\")\n",
    "    f_hz = s2[\"Series2.X\"].to_numpy(float) * 1e3\n",
    "    mu2  = s2[\"Series2.Y\"].to_numpy(float)\n",
    "    if len(f1_hz) == 0 or len(f_hz) == 0:\n",
    "        raise ValueError(\"No valid μ′/μ″ data after cleaning.\")\n",
    "    return f1_hz, mu1_src, f_hz, mu2\n",
    "\n",
    "def export_user(f_hz, mu1_on_f, mu2, out_path: Path):\n",
    "    pd.DataFrame({\"f_Hz\": f_hz, \"mu_prime\": mu1_on_f, \"mu_doubleprime\": mu2}) \\\n",
    "      .to_csv(out_path, sep=\"\\t\", index=False, header=False, float_format=\"%.9f\")\n",
    "\n",
    "# =====================================================================\n",
    "# Helpers\n",
    "# =====================================================================\n",
    "def interp_hold(x_src, y_src, x_new):\n",
    "    return np.interp(x_new, x_src, y_src, left=y_src[0], right=y_src[-1])\n",
    "\n",
    "def hn_complex(mu_inf, dmu, tau, alpha, beta, f_hz):\n",
    "    \"\"\"HN complex μ* with μs = μ∞ + Δμ, using e^{-jωt} (μ″ ≥ 0).\"\"\"\n",
    "    #mu_s = mu_inf + dmu    #If wanted to calculated from data\n",
    "    mu_s = 2156  # Set your desired value here\n",
    "    w = 2*np.pi*f_hz\n",
    "    tau   = max(tau, 1e-15)\n",
    "    alpha = np.clip(alpha, 1e-6, 0.999999)  # CST-safe\n",
    "    beta  = np.clip(beta,  1e-6, 1.0)\n",
    "    jwta  = (-1j*w*tau)**alpha  # sign so μ″ is positive\n",
    "    denom = (1.0 + jwta)**beta\n",
    "    return mu_inf + (mu_s - mu_inf)/denom\n",
    "\n",
    "def overlap_band(f_hz, f1_max):\n",
    "    return (f_hz <= f1_max)\n",
    "\n",
    "def auto_band(f_hz, mu2, ov_mask, low_mult, high_mult):\n",
    "    f_ov, mu2_ov = f_hz[ov_mask], mu2[ov_mask]\n",
    "    if len(f_ov) < 16:\n",
    "        raise ValueError(\"Overlap too small for fitting.\")\n",
    "    p = int(np.nanargmax(mu2_ov))\n",
    "    f_peak = float(f_ov[p])\n",
    "    fmin = max(f_ov[0], f_peak*low_mult)\n",
    "    fmax = min(f_ov[-1], f_peak*high_mult)\n",
    "    return (f_hz >= fmin) & (f_hz <= fmax) & ov_mask, f_peak\n",
    "\n",
    "# =====================================================================\n",
    "# Fitting (with restarts and modes)\n",
    "# =====================================================================\n",
    "def fit_once(f_hz, mu1_on_f, mu2, mask, f_peak,\n",
    "             mu_pp_weight=3.0,\n",
    "             alpha_mode=(\"frozen\", 0.999),\n",
    "             beta_mode=(\"frozen\", 1.0),\n",
    "             restart=(1.0, 1.0, 1.0)):\n",
    "    eps = 1e-9\n",
    "    f_fit   = f_hz[mask]\n",
    "    mu1_fit = mu1_on_f[mask]\n",
    "    mu2_fit = mu2[mask]\n",
    "\n",
    "    # seeds from data\n",
    "    n = len(mu1_fit); k = max(3, n//7)\n",
    "    mu_low  = float(np.median(mu1_fit[:k]))\n",
    "    mu_high = float(np.median(mu1_fit[-k:]))\n",
    "    mu_inf0 = max(1.0, min(mu_high, mu_low)) * restart[2]\n",
    "    dmu_from_mu   = max(5.0, abs(mu_low - mu_high))\n",
    "    dmu_from_mupp = max(5.0, 2.0*float(np.nanmax(mu2_fit)))   # Debye identity\n",
    "    dmu0 = max(dmu_from_mu, dmu_from_mupp) * restart[1]\n",
    "    tau0 = (1.0/(2*np.pi*f_peak)) * restart[0]\n",
    "\n",
    "    # variables θ = [mu_inf, dmu, log10_tau, (alpha?), (beta?)]\n",
    "    th0 = [mu_inf0, dmu0, np.log10(tau0)]\n",
    "    lb  = [0.2*mu_high,  0.1*dmu0, np.log10(tau0/10)]\n",
    "    ub  = [2.0*mu_low,   10.0*dmu0, np.log10(tau0*10)]\n",
    "\n",
    "    alpha_fixed = alpha_mode[1] if alpha_mode[0]==\"frozen\" else None\n",
    "    beta_fixed  = beta_mode[1]  if beta_mode[0]==\"frozen\"  else None\n",
    "    if alpha_fixed is None:\n",
    "        th0.append(0.95); lb.append(0.90); ub.append(0.999)\n",
    "    if beta_fixed is None:\n",
    "        th0.append(1.0);  lb.append(0.85); ub.append(1.0)\n",
    "\n",
    "    th0 = np.array(th0, float); lb = np.array(lb, float); ub = np.array(ub, float)\n",
    "    mu1_scale = max(1.0, np.median(mu1_fit))\n",
    "\n",
    "    def unpack(theta):\n",
    "        i=0\n",
    "        mu_inf = theta[i]; i+=1\n",
    "        dmu    = theta[i]; i+=1\n",
    "        tau    = 10.0**theta[i]; i+=1\n",
    "        alpha  = alpha_fixed if alpha_fixed is not None else theta[i]; i += (0 if alpha_fixed is not None else 1)\n",
    "        beta   = beta_fixed  if beta_fixed  is not None else theta[i]\n",
    "        return mu_inf, dmu, tau, alpha, beta\n",
    "\n",
    "    def resid(theta):\n",
    "        mu_inf, dmu, tau, alpha, beta = unpack(theta)\n",
    "        mu = hn_complex(mu_inf, dmu, tau, alpha, beta, f_fit)\n",
    "        r_real = (mu.real - mu1_fit) / mu1_scale\n",
    "        mu_i = np.maximum(mu.imag, eps)\n",
    "        r_imag = np.log10(mu_i) - np.log10(np.maximum(mu2_fit, eps))\n",
    "        pen = np.minimum(mu.imag, 0.0) * 0.05\n",
    "        return np.hstack([r_real, mu_pp_weight*r_imag, pen])\n",
    "\n",
    "    res = least_squares(resid, th0, bounds=(lb, ub),\n",
    "                        loss=\"soft_l1\", f_scale=0.3,\n",
    "                        xtol=1e-12, ftol=1e-12, gtol=1e-12,\n",
    "                        max_nfev=80000)\n",
    "    mu_inf, dmu, tau, alpha, beta = unpack(res.x)\n",
    "    alpha = min(alpha, 0.999999)  # CST-safe\n",
    "    return (mu_inf, dmu, tau, alpha, beta), res.cost\n",
    "\n",
    "# =====================================================================\n",
    "# Scoring (fixed metric so different trial weights are comparable)\n",
    "# =====================================================================\n",
    "def evaluate_fit(f_hz, mu1_on_f, mu2, params, eval_mask):\n",
    "    eps = 1e-9\n",
    "    mu = hn_complex(*params, f_hz[eval_mask])\n",
    "    mu1_fit = mu1_on_f[eval_mask]\n",
    "    mu1_scale = max(1.0, np.median(mu1_fit))\n",
    "    e_r = (mu.real - mu1_fit)/mu1_scale\n",
    "    rms_r = np.sqrt(np.mean(e_r**2))\n",
    "    mu2_fit = mu2[eval_mask]\n",
    "    e_i = (np.log10(np.maximum(mu.imag, eps))\n",
    "           - np.log10(np.maximum(mu2_fit, eps)))\n",
    "    rms_i = np.sqrt(np.mean(e_i**2))\n",
    "    neg_pen = float(np.sum(np.minimum(mu.imag, 0.0)**2)) * 1e-4\n",
    "    score = rms_r + 3.0*rms_i + neg_pen\n",
    "    return score, rms_r, rms_i\n",
    "\n",
    "# =====================================================================\n",
    "# Main auto-tune\n",
    "# =====================================================================\n",
    "def main():\n",
    "    f1_hz, mu1_src, f_hz, mu2 = load_excel(EXCEL_PATH)\n",
    "    mu1_on_f = interp_hold(f1_hz, mu1_src, f_hz)\n",
    "    export_user(f_hz, mu1_on_f, mu2, USER_OUT)\n",
    "\n",
    "    ov_mask = overlap_band(f_hz, f1_hz.max())\n",
    "\n",
    "    rows = []\n",
    "    best = None  # (score, params, mask, details dict)\n",
    "\n",
    "    for (lb_mult, ub_mult) in BAND_SPREADS:\n",
    "        mask_band, f_peak = auto_band(f_hz, mu2, ov_mask, lb_mult, ub_mult)\n",
    "        eval_mask = mask_band.copy()\n",
    "\n",
    "        for wpp in MU_PP_WEIGHTS:\n",
    "            for a_mode in ALPHA_MODES:\n",
    "                for b_mode in BETA_MODES:\n",
    "                    for rst in RESTARTS:\n",
    "                        params, ls_cost = fit_once(\n",
    "                            f_hz, mu1_on_f, mu2, mask_band, f_peak,\n",
    "                            mu_pp_weight=wpp,\n",
    "                            alpha_mode=a_mode,\n",
    "                            beta_mode=b_mode,\n",
    "                            restart=rst\n",
    "                        )\n",
    "                        score, rms_r, rms_i = evaluate_fit(f_hz, mu1_on_f, mu2,\n",
    "                                                           params, eval_mask)\n",
    "                        mu_inf, dmu, tau, alpha, beta = params\n",
    "                        mu_s = mu_inf + dmu\n",
    "                        row = {\n",
    "                            \"score\": score, \"rms_mu_prime\": rms_r, \"rms_log_mu_dblprime\": rms_i,\n",
    "                            \"mu_infinity\": mu_inf, \"mu_static\": mu_s, \"tau_s\": tau,\n",
    "                            \"alpha\": alpha, \"beta\": beta,\n",
    "                            \"band_low_mult\": lb_mult, \"band_high_mult\": ub_mult,\n",
    "                            \"mu_pp_weight\": wpp,\n",
    "                            \"alpha_mode\": a_mode[0], \"beta_mode\": b_mode[0],\n",
    "                            \"restart_tau_mult\": rst[0], \"restart_dmu_mult\": rst[1], \"restart_muinf_mult\": rst[2],\n",
    "                            \"ls_internal_cost\": ls_cost,\n",
    "                            \"f_eval_min_Hz\": float(f_hz[eval_mask][0]),\n",
    "                            \"f_eval_max_Hz\": float(f_hz[eval_mask][-1]),\n",
    "                            \"f_peak_Hz\": float(f_peak)\n",
    "                        }\n",
    "                        rows.append(row)\n",
    "                        if (best is None) or (score < best[0]):\n",
    "                            best = (score, params, eval_mask, row)\n",
    "\n",
    "    # Save leaderboard\n",
    "    lb_df = pd.DataFrame(rows).sort_values(\"score\").reset_index(drop=True)\n",
    "    lb_df.to_csv(LEADERBOARD, index=False)\n",
    "\n",
    "    # Best result\n",
    "    best_score, best_params, best_mask, best_row = best\n",
    "    mu_inf, dmu, tau, alpha, beta = best_params\n",
    "    mu_s = mu_inf + dmu\n",
    "\n",
    "    # Save best params\n",
    "    pd.DataFrame([{\n",
    "        \"mu_infinity\": mu_inf,\n",
    "        \"mu_static_default\": mu_s,\n",
    "        \"relaxation_time_s\": tau,\n",
    "        \"alpha\": alpha,\n",
    "        \"beta\": beta,\n",
    "        \"score\": best_score\n",
    "    }]).to_csv(BEST_PARAMS, index=False)\n",
    "\n",
    "    # Plot best (μ curves)\n",
    "    mu = hn_complex(mu_inf, dmu, tau, alpha, beta, f_hz)\n",
    "    plt.figure(figsize=(10,8))\n",
    "    if X_SCALE == \"log\": plt.xscale(\"log\")\n",
    "    plt.yscale(Y_SCALE)\n",
    "    plt.plot(f_hz, mu1_on_f, label=\"μ' (target)\")\n",
    "    plt.plot(f_hz, mu2,      label=\"μ'' (target)\")\n",
    "    plt.plot(f_hz, mu.real,  label=\"μ' (Generalized Debye fit)\")\n",
    "    mupp = mu.imag\n",
    "    if Y_SCALE == \"log\":\n",
    "        mupp = np.where(mupp > 0, mupp, np.nan)\n",
    "    else:\n",
    "        mupp = np.maximum(mupp, 0.0)\n",
    "    plt.plot(f_hz, mupp,     label=\"μ'' (Generalized Debye fit)\")\n",
    "    if best_mask is not None and np.any(best_mask):\n",
    "        plt.axvspan(np.min(f_hz[best_mask]), np.max(f_hz[best_mask]),\n",
    "                    color='0.9', alpha=0.35, label=\"Fit band\")\n",
    "    if Y_SCALE == \"linear\":\n",
    "        plt.ylim(bottom=0)\n",
    "    plt.xlabel(\"Frequency [Hz]\"); plt.ylabel(\"Permeability\")\n",
    "    plt.title(\"N87: CST 'User' Data & Generalized Debye (HN) Fit — BEST\")\n",
    "    plt.legend(); plt.tight_layout(); plt.savefig(BEST_PNG, dpi=150)\n",
    "\n",
    "    # ---------------- TOLERANCE ESTIMATES ----------------\n",
    "    eps = 1e-12\n",
    "    f_fit   = f_hz[best_mask]\n",
    "    mu1_meas = mu1_on_f[best_mask]\n",
    "    mu2_meas = mu2[best_mask]\n",
    "    mu_fit   = hn_complex(mu_inf, dmu, tau, alpha, beta, f_fit)\n",
    "\n",
    "    # Reactance / inductance error ≈ μ′ error\n",
    "    rel_err_mu1 = (mu_fit.real - mu1_meas) / np.maximum(mu1_meas, eps)\n",
    "    mu1_med_err = float(np.median(np.abs(rel_err_mu1)))\n",
    "    mu1_max_err = float(np.max(np.abs(rel_err_mu1)))\n",
    "\n",
    "    # Loss / ESR error ≈ μ″ error (where μ″ is significant)\n",
    "    mu2_pk = float(np.max(mu2_meas))\n",
    "    loss_mask = mu2_meas > (0.1 * mu2_pk)\n",
    "    if not np.any(loss_mask):\n",
    "        loss_mask = np.ones_like(mu2_meas, dtype=bool)\n",
    "    rel_err_mu2 = (mu_fit.imag - mu2_meas) / np.maximum(mu2_meas, eps)\n",
    "    mu2_med_err = float(np.median(np.abs(rel_err_mu2[loss_mask])))\n",
    "    mu2_max_err = float(np.max(np.abs(rel_err_mu2[loss_mask])))\n",
    "\n",
    "    # Suggested loss scale factors (measured/model)\n",
    "    loss_ratio = np.maximum(mu2_meas[loss_mask], eps) / np.maximum(mu_fit.imag[loss_mask], eps)\n",
    "    scale_med  = float(np.median(loss_ratio))\n",
    "    scale_p90  = float(np.percentile(loss_ratio, 90))\n",
    "\n",
    "    # ---------------- ERROR VS FREQUENCY (LOG Y, ABS % ERRORS) ----------------\n",
    "    ov_mask_full = overlap_band(f_hz, f1_hz.max())\n",
    "    mu_all       = hn_complex(mu_inf, dmu, tau, alpha, beta, f_hz)\n",
    "\n",
    "    err_mu1_pct = np.full_like(f_hz, np.nan, float)\n",
    "    err_mu2_pct = np.full_like(f_hz, np.nan, float)\n",
    "    err_q_pct   = np.full_like(f_hz, np.nan, float)\n",
    "\n",
    "    # μ′ error where overlap exists\n",
    "    err_mu1_pct[ov_mask_full] = 100.0 * (mu_all.real[ov_mask_full] - mu1_on_f[ov_mask_full]) / \\\n",
    "                                np.maximum(mu1_on_f[ov_mask_full], eps)\n",
    "\n",
    "    # μ″ error only where μ″ is meaningful (>= 10% of peak inside overlap)\n",
    "    mu2_ov = mu2[ov_mask_full]; pk = np.nanmax(mu2_ov)\n",
    "    good_loss = ov_mask_full & (mu2 >= 0.1 * pk)\n",
    "    err_mu2_pct[good_loss] = 100.0 * (mu_all.imag[good_loss] - mu2[good_loss]) / \\\n",
    "                             np.maximum(mu2[good_loss], eps)\n",
    "\n",
    "    # Q error where loss is meaningful\n",
    "    q_meas = np.full_like(f_hz, np.nan, float)\n",
    "    q_fit  = np.full_like(f_hz, np.nan, float)\n",
    "    q_meas[good_loss] = mu1_on_f[good_loss] / np.maximum(mu2[good_loss], eps)\n",
    "    q_fit[good_loss]  = mu_all.real[good_loss] / np.maximum(mu_all.imag[good_loss], eps)\n",
    "    err_q_pct[good_loss] = 100.0 * (q_fit[good_loss] - q_meas[good_loss]) / np.maximum(q_meas[good_loss], eps)\n",
    "\n",
    "    # semilogy of ABSOLUTE % errors\n",
    "    epsy = 1e-2  # floor = 0.01% to avoid log(0)\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.xscale(\"log\")\n",
    "    plt.semilogy(f_hz, np.where(np.isfinite(err_mu1_pct), np.maximum(np.abs(err_mu1_pct), epsy), np.nan),\n",
    "                 label=\"|μ′ error| → |X_L| error [%]\")\n",
    "    plt.semilogy(f_hz, np.where(np.isfinite(err_mu2_pct), np.maximum(np.abs(err_mu2_pct), epsy), np.nan),\n",
    "                 label=\"|μ″ error| → |ESR_core| error [%]\")\n",
    "    plt.semilogy(f_hz, np.where(np.isfinite(err_q_pct),   np.maximum(np.abs(err_q_pct),   epsy), np.nan),\n",
    "                 label=\"|Q error| [%]\", linestyle=\":\")\n",
    "\n",
    "    # reference lines\n",
    "    for y in [1, 5, 10]:\n",
    "        plt.axhline(y, color=\"0.85\", lw=0.8, zorder=0)\n",
    "        plt.text(f_hz[0]*1.05, y*1.03, f\"{y}%\", color=\"0.5\", fontsize=9, va=\"bottom\")\n",
    "\n",
    "    if best_mask is not None and np.any(best_mask):\n",
    "        plt.axvspan(np.min(f_hz[best_mask]), np.max(f_hz[best_mask]),\n",
    "                    color='0.9', alpha=0.35, label=\"Fit band\")\n",
    "    plt.xlabel(\"Frequency [Hz]\")\n",
    "    plt.ylabel(\"Absolute relative error [%] (log scale)\")\n",
    "    plt.title(\"HN fit error vs frequency (impedance-related)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(ERROR_PNG, dpi=150)\n",
    "\n",
    "    # Console summary + sanity check\n",
    "    print(\"\\nBest HN parameters (single term, CST-safe):\")\n",
    "    print(f\"  mu_infinity      = {mu_inf:.6g}\")\n",
    "    print(f\"  mu_static (def.) = {mu_s:.6g}   (Δμ = {dmu:.6g})\")\n",
    "    print(f\"  tau [s]          = {tau:.6e}\")\n",
    "    print(f\"  alpha            = {alpha:.6g}  (< 1.0)\")\n",
    "    print(f\"  beta             = {beta:.6g}\")\n",
    "    print(f\"  Score            = {best_score:.6g}\")\n",
    "    f_peak_pred = 1.0/(2*np.pi*tau)\n",
    "    print(f\"  Sanity: predicted f_peak ≈ {f_peak_pred:.3g} Hz,  μ\\\"_max ≈ {0.5*dmu:.2f}\")\n",
    "\n",
    "    print(\"\\nEstimated tolerances in the fit band:\")\n",
    "    print(f\"  Reactance / inductance (≈ μ′): median ±{mu1_med_err*100:.1f}%, max ±{mu1_max_err*100:.1f}%\")\n",
    "    print(f\"  Core loss / ESR (≈ μ″):       median ±{mu2_med_err*100:.1f}%, max ±{mu2_max_err*100:.1f}%\")\n",
    "    print(f\"  Suggested loss scale (meas/model): median ×{scale_med:.2f}, 90th pct ×{scale_p90:.2f}\")\n",
    "\n",
    "    print(\"\\nFiles:\")\n",
    "    print(f\"  User export      : {USER_OUT}\")\n",
    "    print(f\"  Best params CSV  : {BEST_PARAMS}\")\n",
    "    print(f\"  Leaderboard CSV  : {LEADERBOARD}\")\n",
    "    print(f\"  Best-fit plot    : {BEST_PNG}\")\n",
    "    print(f\"  Error plot       : {ERROR_PNG}\")\n",
    "    print(\"\\nPaste μ∞, μs (default), τ, α, β into CST → Magnetic → Dispersion → Generalized Debye,\")\n",
    "    print(\"then enable Field dependency → B–H curve to include saturation.\")\n",
    "    print(\"Use the loss scale factor to bracket temperature rise/efficiency if needed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c5c143",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
