{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cd166b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a59c3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TDK PDFs: 100%|██████████| 772/772 [00:46<00:00, 16.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned DataFrame with geometry → TDK_E_and_Toroid_Cores_no_catalog_cleaned.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# parser_elarge_fallback.py\n",
    "import re, time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import fitz  # PyMuPDF\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "# ---------------- SETTINGS ----------------\n",
    "INPUT_CSV  = \"TDK_E_and_Toroid_Cores_no_catalog.csv\"\n",
    "ID_COL     = \"Part No.\"\n",
    "URL_COL    = \"Catalog / Data Sheet\"\n",
    "AL_COL     = \"AL Value / (nH / N²)\"\n",
    "BS_COL     = \"Saturation Magnetic Flux Density Bs / mT\"\n",
    "GAP_COL    = \"Air Gap / mm\"\n",
    "MUI_COL    = \"Initial Permeability μi\"\n",
    "MAT_COL    = \"Material Name\"\n",
    "SHAPE_COLS = [\"Core Shape\", \"Shape\"]\n",
    "\n",
    "CACHE_DIR  = Path(\"pdf_cache\")\n",
    "SLEEP_BETWEEN = 0.0\n",
    "STOP_ON_DOWNLOAD_FAILURE = False\n",
    "CLEANED_CSV = \"TDK_E_and_Toroid_Cores_no_catalog_cleaned.csv\"\n",
    "# -------------------------------------------\n",
    "\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- HTTP session with retries ---\n",
    "session = requests.Session()\n",
    "retries = Retry(total=5, connect=3, read=5, backoff_factor=1.5,\n",
    "                status_forcelist=[429, 500, 502, 503, 504],\n",
    "                allowed_methods=[\"GET\", \"HEAD\", \"OPTIONS\"])\n",
    "adapter = HTTPAdapter(max_retries=retries, pool_connections=2, pool_maxsize=2)\n",
    "session.mount(\"https://\", adapter)\n",
    "session.mount(\"http://\", adapter)\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0\",\n",
    "    \"Referer\": \"https://product.tdk.com/\",\n",
    "    \"Accept\": \"application/pdf,*/*;q=0.9\",\n",
    "}\n",
    "\n",
    "def download_pdf(url: str, dest: Path) -> bool:\n",
    "    try:\n",
    "        if dest.exists() and dest.stat().st_size > 1024:\n",
    "            return True\n",
    "        with session.get(url, headers=HEADERS, timeout=(10, 180), stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            if \"pdf\" not in (r.headers.get(\"Content-Type\") or \"\").lower():\n",
    "                raise ValueError(f\"Non-PDF content-type: {r.headers.get('Content-Type')}\")\n",
    "            with open(dest, \"wb\") as f:\n",
    "                for chunk in r.iter_content(65536):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Download failed: {url} -> {e}\")\n",
    "        return False\n",
    "\n",
    "# ========= Patterns & cleaners (robust to OCR and grouping) =========\n",
    "PAT_MM1 = r\"m\\s*m\"\n",
    "PAT_MM2 = r\"m\\s*m\\s*(?:2|\\^?\\s*2|²)\"\n",
    "PAT_MM3 = r\"m\\s*m\\s*(?:3|\\^?\\s*3|³)\"\n",
    "\n",
    "# wide number: 102 000 | 102 000 | 102,000 | 102000 | 683.5\n",
    "PAT_NUM_WIDE = r\"([-+]?(?:\\d{1,3}(?:[ \\u00A0,]\\d{3})+|\\d+)(?:[.,]\\d+)?)\"\n",
    "PUNCT_OPT = r\"(?:[:=≈])?\"\n",
    "\n",
    "def _lab(tag):          # 'ae' -> A[_ ]?e\n",
    "    return rf\"(?:{tag[0]}\\s*[_ ]?\\s*{tag[1]})\"\n",
    "\n",
    "def _lab_any_l_e():     # tolerate l/I/ℓ for 'le'\n",
    "    return r\"(?:[lIℓ]\\s*[_ ]?\\s*e)\"\n",
    "\n",
    "def _clean_num_wide(s: str | None):\n",
    "    if not s:\n",
    "        return None\n",
    "    s = (str(s)\n",
    "         .replace(\"\\u2212\",\"-\").replace(\"\\u2013\",\"-\")\n",
    "         .replace(\"\\u00A0\",\" \").strip())\n",
    "    s = s.replace(\",\", \".\")                      # comma -> decimal point\n",
    "    s = re.sub(r\"(?<=\\d)[ ](?=\\d{3}\\b)\", \"\", s)  # remove thousand spaces\n",
    "    s = re.sub(r\"[^\\d.+\\-eE]\", \"\", s)\n",
    "    try:\n",
    "        return float(s)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def read_pdf_fulltext(pdf_path: Path) -> str:\n",
    "    try:\n",
    "        doc = fitz.open(str(pdf_path))\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "    pages = []\n",
    "    for p in doc:\n",
    "        t = p.get_text(\"text\")\n",
    "        t = (t.replace(\"²\",\"2\").replace(\"³\",\"3\")\n",
    "               .replace(\"\\u2212\",\"-\").replace(\"\\u00A0\",\" \"))\n",
    "        pages.append(t)\n",
    "    doc.close()\n",
    "    return \"\\n\".join(pages)\n",
    "\n",
    "def _slice_magnetic_block(txt: str) -> str | None:\n",
    "    m = re.search(r\"Magnetic\\s+characteristics\", txt, flags=re.IGNORECASE)\n",
    "    if not m:\n",
    "        return None\n",
    "    win = txt[m.end(): m.end()+12000]\n",
    "    cut = re.search(r\"\\b(Gapped|Accessories|Calculation\\s+factors|Coil\\s+former|Symbols and terms)\\b\",\n",
    "                    win, flags=re.IGNORECASE)\n",
    "    return win[:cut.start()] if cut else win\n",
    "\n",
    "# --- Generic E-family patterns (now wide-number + optional punctuation)\n",
    "GEN_LE = re.compile(rf\"\\b{_lab_any_l_e()}\\s*{PUNCT_OPT}\\s*{PAT_NUM_WIDE}\\s*{PAT_MM1}\\b\",\n",
    "                    re.IGNORECASE | re.DOTALL)\n",
    "GEN_AE = re.compile(rf\"\\b{_lab('ae')}\\s*{PUNCT_OPT}\\s*{PAT_NUM_WIDE}\\s*{PAT_MM2}\\b\",\n",
    "                    re.IGNORECASE | re.DOTALL)\n",
    "GEN_VE = re.compile(rf\"\\b{_lab('ve')}\\s*{PUNCT_OPT}\\s*{PAT_NUM_WIDE}\\s*{PAT_MM3}\\b\",\n",
    "                    re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "# --- E(Large) patterns (same as generic; kept separate in case PDFs vary)\n",
    "EL_LE = GEN_LE\n",
    "EL_AE = GEN_AE\n",
    "EL_VE = GEN_VE\n",
    "\n",
    "def parse_generic_e(full_text: str):\n",
    "    txt = _slice_magnetic_block(full_text) or full_text\n",
    "    le  = _clean_num_wide(next((m.group(1) for m in GEN_LE.finditer(txt)), None))\n",
    "    ae  = _clean_num_wide(next((m.group(1) for m in GEN_AE.finditer(txt)), None))\n",
    "    ve  = _clean_num_wide(next((m.group(1) for m in GEN_VE.finditer(txt)), None))\n",
    "    # physics backfill\n",
    "    if ae is None and (le is not None) and (ve is not None) and le > 0: ae = ve / le\n",
    "    if le is None and (ae is not None) and (ve is not None) and ae > 0: le = ve / ae\n",
    "    if ve is None and (ae is not None) and (le is not None):           ve = ae * le\n",
    "    return (le, ae, ve)\n",
    "\n",
    "def parse_e_large_geom(pdf_path: Path):\n",
    "    txt_full = read_pdf_fulltext(pdf_path)\n",
    "    txt = _slice_magnetic_block(txt_full) or txt_full\n",
    "    le  = _clean_num_wide(next((m.group(1) for m in EL_LE.finditer(txt)), None))\n",
    "    ae  = _clean_num_wide(next((m.group(1) for m in EL_AE.finditer(txt)), None))\n",
    "    ve  = _clean_num_wide(next((m.group(1) for m in EL_VE.finditer(txt)), None))\n",
    "    if ae is None and (le is not None) and (ve is not None) and le > 0: ae = ve / le\n",
    "    if le is None and (ae is not None) and (ve is not None) and ae > 0: le = ve / ae\n",
    "    if ve is None and (ae is not None) and (le is not None):           ve = ae * le\n",
    "    return {\n",
    "        \"Sigma_l_over_A_mm_inv\": None,\n",
    "        \"le_m\":  le*1e-3  if le is not None else None,\n",
    "        \"Ae_m2\": ae*1e-6  if ae is not None else None,\n",
    "        \"Ve_m3\": ve*1e-9  if ve is not None else None,\n",
    "    }\n",
    "\n",
    "# ========= Toroid (Ring) helpers (unchanged) =========\n",
    "def _num_tolerant(s: str):\n",
    "    if s is None: return None\n",
    "    s = (str(s).replace(\"\\u2212\",\"-\").replace(\"\\u2013\",\"-\").replace(\"\\u00A0\",\" \").replace(\",\", \".\").strip())\n",
    "    m = re.search(r\"[-+]?\\d+(?:\\.\\d+)?\", s)\n",
    "    return float(m.group(0)) if m else None\n",
    "\n",
    "def normalize_ordering_code(s: str) -> str:\n",
    "    s = str(s or \"\")\n",
    "    s = re.sub(r\"\\s*\\(.*?\\)\\s*$\", \"\", s)\n",
    "    m = re.search(r\"(B[0-9A-Z]+)\", s.upper())\n",
    "    return m.group(1) if m else s.split()[0]\n",
    "\n",
    "def read_pdf_text(pdf_path: Path) -> tuple[str, list[str]]:\n",
    "    doc = fitz.open(pdf_path)\n",
    "    pages = [page.get_text(\"text\") for page in doc]\n",
    "    doc.close()\n",
    "    return \"\\n\".join(pages), pages\n",
    "\n",
    "def _quartet_after_code(text: str, code: str):\n",
    "    pat = rf\"{re.escape(code)}\\s+(?P<slA>[-+]?\\d+(?:[.,]\\d+)?)\\s+(?P<le>[-+]?\\d+(?:[.,]\\d+)?)\\s+(?P<Ae>[-+]?\\d+(?:[.,]\\d+)?)\\s+(?P<Ve>[-+]?\\d+(?:[.,]\\d+)?)\"\n",
    "    return re.search(pat, text, flags=re.IGNORECASE)\n",
    "\n",
    "def _plausible(g):\n",
    "    slA=_num_tolerant(g.get(\"slA\")); le=_num_tolerant(g.get(\"le\")); Ae=_num_tolerant(g.get(\"Ae\")); Ve=_num_tolerant(g.get(\"Ve\"))\n",
    "    if None in (slA, le, Ae, Ve): return None\n",
    "    if not (0.05 <= slA <= 500): return None\n",
    "    if not (1    <= le  <= 2000): return None\n",
    "    if not (0.05 <= Ae  <= 1e4): return None\n",
    "    if not (1    <= Ve  <= 1e8): return None\n",
    "    return slA, le, Ae, Ve\n",
    "\n",
    "def _header_quartet_tokenwise(text: str):\n",
    "    hdr = re.search(r\"Magnetic\\s+characteristics\", text, flags=re.IGNORECASE)\n",
    "    if not hdr: return None\n",
    "    window = text[hdr.end(): hdr.end()+12000]\n",
    "    toks = [m.group(0) for m in re.finditer(r\"[-+]?\\d+(?:[.,]\\d+)?\", window)]\n",
    "    def is_dec(s): return \".\" in s or \",\" in s\n",
    "    for i in range(len(toks)-3):\n",
    "        a,b,c,d = toks[i:i+4]\n",
    "        if len(a)==3 and a.isdigit(): continue\n",
    "        if not (is_dec(a) and is_dec(b) and is_dec(c)): continue\n",
    "        try: fa,fb,fc,fd=(float(a.replace(\",\", \".\")),float(b.replace(\",\", \".\")),float(c.replace(\",\", \".\")),float(d.replace(\",\", \".\")))\n",
    "        except ValueError: continue\n",
    "        if 0.05<=fa<=500 and 1<=fb<=2000 and 0.05<=fc<=1e4 and 1<=fd<=1e8:\n",
    "            return fa,fb,fc,fd\n",
    "    return None\n",
    "\n",
    "def parse_toroid_magnetic_characteristics(pdf_path: Path, ordering_code_raw: str):\n",
    "    full_text, pages = read_pdf_text(pdf_path)\n",
    "    part = ordering_code_raw.strip()\n",
    "    norm = normalize_ordering_code(part)\n",
    "\n",
    "    for code in (part, norm if norm != part else None):\n",
    "        if not code: continue\n",
    "        m = _quartet_after_code(full_text, code)\n",
    "        if m:\n",
    "            pl = _plausible(m.groupdict())\n",
    "            if pl:\n",
    "                slA, le, Ae, Ve = pl\n",
    "                return {\"Sigma_l_over_A_mm_inv\": slA, \"le_m\": le*1e-3, \"Ae_m2\": Ae*1e-6, \"Ve_m3\": Ve*1e-9}\n",
    "\n",
    "    page_idx = next((i for i, pg in enumerate(pages) if (part in pg) or (norm and norm in pg)), None)\n",
    "    if page_idx is not None:\n",
    "        pl = _header_quartet_tokenwise(pages[page_idx])\n",
    "        if pl:\n",
    "            slA, le, Ae, Ve = pl\n",
    "            return {\"Sigma_l_over_A_mm_inv\": slA, \"le_m\": le*1e-3, \"Ae_m2\": Ae*1e-6, \"Ve_m3\": Ve*1e-9}\n",
    "\n",
    "    pl = _header_quartet_tokenwise(full_text)\n",
    "    if pl:\n",
    "        slA, le, Ae, Ve = pl\n",
    "        return {\"Sigma_l_over_A_mm_inv\": slA, \"le_m\": le*1e-3, \"Ae_m2\": Ae*1e-6, \"Ve_m3\": Ve*1e-9}\n",
    "\n",
    "    return {\"Sigma_l_over_A_mm_inv\": None, \"le_m\": None, \"Ae_m2\": None, \"Ve_m3\": None}\n",
    "\n",
    "# ========= Planar ER detector & parser =========\n",
    "PLANAR_HINTS = {\"ER\", \"PLANAR\", \"EER\", \"EIR\"}\n",
    "def is_planar_er(row: pd.Series) -> bool:\n",
    "    for key in [\"core_shape\",\"Family\",\"Core Shape\",\"Core Type\",\"Core type\"]:\n",
    "        val = str(row.get(key, \"\") or \"\").upper()\n",
    "        if any(h in val for h in PLANAR_HINTS): return True\n",
    "    url = str(row.get(URL_COL, \"\") or \"\").upper()\n",
    "    if any(h in url for h in PLANAR_HINTS): return True\n",
    "    pn = str(row.get(ID_COL, \"\") or \"\").upper()\n",
    "    if re.search(r\"\\bB65(5|6)\\d{2}\", pn) and any(h in url for h in PLANAR_HINTS): return True\n",
    "    return False\n",
    "\n",
    "PAT_LE_ER = GEN_LE; PAT_AE_ER = GEN_AE; PAT_VE_ER = GEN_VE\n",
    "\n",
    "def _clean_float_relaxed(s): return _clean_num_wide(s)\n",
    "\n",
    "def parse_planar_er_geom(pdf_path: Path):\n",
    "    txt = read_pdf_fulltext(pdf_path)\n",
    "    le  = _clean_float_relaxed(next((m.group(1) for m in PAT_LE_ER.finditer(txt)), None))\n",
    "    ae  = _clean_float_relaxed(next((m.group(1) for m in PAT_AE_ER.finditer(txt)), None))\n",
    "    ve  = _clean_float_relaxed(next((m.group(1) for m in PAT_VE_ER.finditer(txt)), None))\n",
    "    if ae is None and (le is not None) and (ve is not None) and le > 0: ae = ve / le\n",
    "    if le is None and (ae is not None) and (ve is not None) and ae > 0: le = ve / ae\n",
    "    if ve is None and (ae is not None) and (le is not None):           ve = ae * le\n",
    "    return {\"Sigma_l_over_A_mm_inv\": None, \"le_m\": le*1e-3 if le is not None else None,\n",
    "            \"Ae_m2\": ae*1e-6 if ae is not None else None, \"Ve_m3\": ve*1e-9 if ve is not None else None}\n",
    "\n",
    "# ========= Cache finder =========\n",
    "def find_cached_pdf(part_raw: str, cache_dir: Path) -> Path | None:\n",
    "    oc = normalize_ordering_code(part_raw) or part_raw\n",
    "    p = cache_dir / f\"{oc}.pdf\"\n",
    "    if p.exists() and p.stat().st_size > 1024: return p\n",
    "    hits = sorted(cache_dir.glob(f\"{oc}*.pdf\"))\n",
    "    if hits: return hits[0]\n",
    "    fam = oc[:9]\n",
    "    hits = sorted(cache_dir.glob(f\"{fam}*.pdf\"))\n",
    "    if hits: return hits[0]\n",
    "    for q in cache_dir.glob(\"*.pdf\"):\n",
    "        if oc in q.stem: return q\n",
    "    return None\n",
    "\n",
    "# ---------- load & clean CSV ----------\n",
    "df = pd.read_csv(INPUT_CSV, dtype=str, low_memory=False)\n",
    "\n",
    "if MAT_COL in df.columns:\n",
    "    df[\"material_name\"] = (df[MAT_COL].astype(str)\n",
    "                           .str.replace(r'[\"\\']',\"\",regex=True)\n",
    "                           .str.strip()\n",
    "                           .replace({\"nan\":np.nan,\"None\":np.nan,\"\":np.nan}))\n",
    "else:\n",
    "    df[\"material_name\"] = np.nan\n",
    "\n",
    "shape_src = next((c for c in SHAPE_COLS if c in df.columns), None)\n",
    "if shape_src:\n",
    "    df[\"core_shape\"] = (df[shape_src].astype(str)\n",
    "                        .str.replace(r'[\"\\']',\"\",regex=True)\n",
    "                        .str.strip()\n",
    "                        .replace({\"nan\":np.nan,\"None\":np.nan,\"\":np.nan}))\n",
    "else:\n",
    "    df[\"core_shape\"] = np.nan\n",
    "\n",
    "# Clean CSV values → SI\n",
    "df[\"A_L_clean\"] = (df[AL_COL].astype(str)\n",
    "                    .str.replace(\"\\u2212\",\"-\",regex=False)\n",
    "                    .str.extract(r\"([\\d]+(?:[\\,\\.]\\d+)?)\")[0]\n",
    "                    .str.replace(\",\",\".\",regex=False))\n",
    "df[\"A_L_H_per_turn2\"] = pd.to_numeric(df[\"A_L_clean\"], errors=\"coerce\") * 1e-9\n",
    "\n",
    "df[\"B_s_clean\"] = (df[BS_COL].astype(str)\n",
    "                    .str.replace(\"\\u2212\",\"-\",regex=False)\n",
    "                    .str.extract(r\"([\\d]+(?:[\\,\\.]\\d+)?)\")[0]\n",
    "                    .str.replace(\",\",\".\",regex=False))\n",
    "df[\"B_s_T\"] = pd.to_numeric(df[\"B_s_clean\"], errors=\"coerce\") * 1e-3\n",
    "\n",
    "if GAP_COL in df.columns:\n",
    "    df[\"gap_clean\"] = (df[GAP_COL].astype(str)\n",
    "                        .str.extract(r\"([-+]?\\d+(?:[.,]\\d+)?)\")[0]\n",
    "                        .str.replace(\",\",\".\",regex=False))\n",
    "    df[\"gap_m\"] = pd.to_numeric(df[\"gap_clean\"], errors=\"coerce\") * 1e-3\n",
    "else:\n",
    "    df[\"gap_m\"] = np.nan\n",
    "\n",
    "df[\"mu_i\"] = pd.to_numeric(df[MUI_COL], errors=\"coerce\") if MUI_COL in df.columns else np.nan\n",
    "\n",
    "# ---------- PDF extraction loop ----------\n",
    "rows = []\n",
    "for i, row in tqdm(df.iterrows(), total=len(df), desc=\"TDK PDFs\"):\n",
    "    url_raw  = str(row.get(URL_COL, \"\") or \"\")\n",
    "    part_raw = str(row.get(ID_COL, f\"row{i}\") or \"\").strip()\n",
    "\n",
    "    oc = normalize_ordering_code(part_raw) or part_raw\n",
    "    pdf_path = CACHE_DIR / f\"{oc}.pdf\"\n",
    "\n",
    "    ok = False\n",
    "    cached = find_cached_pdf(part_raw, CACHE_DIR)\n",
    "    if cached:\n",
    "        pdf_path = cached; ok = True\n",
    "    elif pdf_path.exists() and pdf_path.stat().st_size > 1024:\n",
    "        ok = True\n",
    "    elif url_raw.lower().endswith(\".pdf\"):\n",
    "        ok = download_pdf(url_raw, pdf_path)\n",
    "\n",
    "    if not ok:\n",
    "        if STOP_ON_DOWNLOAD_FAILURE:\n",
    "            raise SystemExit(f\"Failed to obtain PDF: {url_raw}\")\n",
    "        rows.append({\"row\": i, \"Sigma_l_over_A_mm_inv\": None, \"le_m\": None, \"Ae_m2\": None, \"Ve_m3\": None})\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # 1) Toroids first\n",
    "        if \"ring\" in url_raw.lower() or \"toroid\" in url_raw.lower():\n",
    "            geom = parse_toroid_magnetic_characteristics(pdf_path, part_raw)\n",
    "        else:\n",
    "            # 2) Generic E parse on the full text\n",
    "            full_text = read_pdf_fulltext(pdf_path)\n",
    "            le, ae, ve = parse_generic_e(full_text)\n",
    "            # 3) If anything missing, try the E(Large) parser (works for that family style)\n",
    "            if (le is None) or (ae is None) or (ve is None):\n",
    "                geom = parse_e_large_geom(pdf_path)\n",
    "            else:\n",
    "                geom = {\"Sigma_l_over_A_mm_inv\": None,\n",
    "                        \"le_m\": le*1e-3, \"Ae_m2\": ae*1e-6, \"Ve_m3\": ve*1e-9}\n",
    "            # 4) If still missing and hints say planar ER, try ER parser\n",
    "            if (geom[\"le_m\"] is None or geom[\"Ae_m2\"] is None or geom[\"Ve_m3\"] is None) and is_planar_er(row):\n",
    "                geom = parse_planar_er_geom(pdf_path)\n",
    "            # 5) Last resort: toroid parse if URL hints it but earlier checks missed\n",
    "            if (geom[\"le_m\"] is None and geom[\"Ae_m2\"] is None and geom[\"Ve_m3\"] is None):\n",
    "                if \"ring\" in url_raw.lower() or \"toroid\" in url_raw.lower():\n",
    "                    geom = parse_toroid_magnetic_characteristics(pdf_path, part_raw)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Parse failed for {part_raw} ({pdf_path}): {e}\")\n",
    "        geom = {\"Sigma_l_over_A_mm_inv\": None, \"le_m\": None, \"Ae_m2\": None, \"Ve_m3\": None}\n",
    "\n",
    "    geom[\"row\"] = i\n",
    "    rows.append(geom)\n",
    "    if SLEEP_BETWEEN:\n",
    "        time.sleep(SLEEP_BETWEEN)\n",
    "\n",
    "geom_df = pd.DataFrame(rows).set_index(\"row\")\n",
    "df = df.join(geom_df, how=\"left\")\n",
    "\n",
    "# ---------- Save ----------\n",
    "df.to_csv(CLEANED_CSV, index=False)\n",
    "print(f\"Saved cleaned DataFrame with geometry → {CLEANED_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca0f297",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
